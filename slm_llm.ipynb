{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37d89f0",
   "metadata": {},
   "source": [
    "# Person7 â€” Relation Extraction, Normalization & Summarization\n",
    "\n",
    "Single-file Jupyter notebook implementing the full Person7 pipeline for your case study.\n",
    "\n",
    "This notebook is self-contained and includes sample data so you can run it immediately.\n",
    "\n",
    "What it contains (in order):\n",
    "1. Setup & sample data creation\n",
    "2. Utilities and helper functions\n",
    "3. Relation extraction (rule-based SLM baseline)\n",
    "4. Entity normalization (simple dictionary + fuzzy matching via difflib)\n",
    "5. Extractive summarization baseline\n",
    "6. Small manual annotation + evaluation (precision/recall/F1)\n",
    "7. Simple plots (top drugs by ADE count, relation distribution)\n",
    "8. Notes on how to plug into your existing pipeline and optionally call an LLM\n",
    "\n",
    "Run all cells in order. Replace sample files with your real Person2 outputs to process real data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, difflib, math\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Path('data/dictionaries').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/cleaned').mkdir(parents=True, exist_ok=True)\n",
    "Path('results').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Working dir:', os.getcwd())\n",
    "print('Directories ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32664c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "sample_extractions_path = Path('results/extractions.json')\n",
    "if not sample_extractions_path.exists():\n",
    "    sample_data = [\n",
    "        {'id':'doc1_sent1','sentence':'Patient developed nausea after taking paracetamol.','drugs':['paracetamol'],'events':['nausea'],'source':'FAERS'},\n",
    "        {'id':'doc1_sent2','sentence':'After starting ibuprofen the patient reported stomach pain and vomiting.','drugs':['ibuprofen'],'events':['stomach pain','vomiting'],'source':'PubMed'},\n",
    "        {'id':'doc2_sent1','sentence':'Headache was reported, possibly related to metformin use.','drugs':['metformin'],'events':['headache'],'source':'FAERS'},\n",
    "        {'id':'doc3_sent2','sentence':'No drug was mentioned but patient had severe dizziness.','drugs':[],'events':['dizziness'],'source':'PubMed'},\n",
    "        {'id':'doc4_sent1','sentence':'Patient experienced rash following antibiotic therapy (amoxicillin).','drugs':['amoxicillin'],'events':['rash'],'source':'FAERS'},\n",
    "        {'id':'doc5_sent1','sentence':'Vomiting occurred but causality with drug is unclear.','drugs':['paracetamol'],'events':['vomiting'],'source':'PubMed'}\n",
    "    ]\n",
    "    with open(sample_extractions_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(sample_data, f, indent=2, ensure_ascii=False)\n",
    "    print('Created sample results/extractions.json')\n",
    "else:\n",
    "    print('Found existing results/extractions.json - leaving it intact.')\n",
    "\n",
    "drugs_csv = Path('data/dictionaries/drugs.csv')\n",
    "if not drugs_csv.exists():\n",
    "    drugs_dict = [\n",
    "        {'name':'paracetamol','id':'DB00316','atc':'N02BE01'},\n",
    "        {'name':'ibuprofen','id':'DB01050','atc':'M01AE01'},\n",
    "        {'name':'metformin','id':'DB00331','atc':'A10BA02'},\n",
    "        {'name':'amoxicillin','id':'DB01060','atc':'J01CA04'}\n",
    "    ]\n",
    "    pd.DataFrame(drugs_dict).to_csv(drugs_csv, index=False)\n",
    "    print('Created sample data/dictionaries/drugs.csv')\n",
    "else:\n",
    "    print('Found existing data/dictionaries/drugs.csv')\n",
    "\n",
    "meddra_csv = Path('data/dictionaries/meddra.csv')\n",
    "if not meddra_csv.exists():\n",
    "    meddra_list = [\n",
    "        {'term':'nausea','code':'10028813'},\n",
    "        {'term':'stomach pain','code':'10012345'},\n",
    "        {'term':'vomiting','code':'10047700'},\n",
    "        {'term':'headache','code':'10019211'},\n",
    "        {'term':'dizziness','code':'10013384'},\n",
    "        {'term':'rash','code':'10039906'}\n",
    "    ]\n",
    "    pd.DataFrame(meddra_list).to_csv(meddra_csv, index=False)\n",
    "    print('Created sample data/dictionaries/meddra.csv')\n",
    "else:\n",
    "    print('Found existing data/dictionaries/meddra.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import json, re, difflib, os\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(obj: Any, path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def load_dict_csv(path: str, key_col: str = 'name') -> Dict[str, dict]:\n",
    "    d = {}\n",
    "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for r in reader:\n",
    "            d[r[key_col].strip().lower()] = r\n",
    "    return d\n",
    "\n",
    "def simple_normalize(text: str) -> str:\n",
    "    if not text:\n",
    "        return ''\n",
    "    return re.sub(r'[^a-z0-9 ]','', text.lower()).strip()\n",
    "\n",
    "def fuzzy_match_difflib(term: str, candidates: List[str], cutoff: float = 0.6) -> Tuple[str, float]:\n",
    "    if not term or not candidates:\n",
    "        return None, 0.0\n",
    "    matches = difflib.get_close_matches(term, candidates, n=1, cutoff=cutoff)\n",
    "    if not matches:\n",
    "        return None, 0.0\n",
    "    match = matches[0]\n",
    "    seq = difflib.SequenceMatcher(None, term, match)\n",
    "    return match, seq.ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fecc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation extraction (rule-based baseline)\n",
    "\n",
    "CAUSAL_WORDS = [\n",
    "    'caused','causing','cause','associated with','associated','led to',\n",
    "    'resulted in','reported','due to','after','following','induced','secondary to',\n",
    "    'related to','triggered','following'\n",
    "]\n",
    "\n",
    "def sentence_contains_cue(sentence: str) -> bool:\n",
    "    s = sentence.lower()\n",
    "    return any(cue in s for cue in CAUSAL_WORDS)\n",
    "\n",
    "def relation_rule_based(entry: dict) -> List[dict]:\n",
    "    # For each (drug,event) pair produce a relation dict using heuristics\n",
    "    sentence = entry.get('sentence','')\n",
    "    drugs = entry.get('drugs',[]) or []\n",
    "    events = entry.get('events',[]) or []\n",
    "    relations = []\n",
    "    tokens = re.findall(r'\\\\w+', sentence.lower())\n",
    "    for d in drugs:\n",
    "        for e in events:\n",
    "            r = {'drug': d, 'event': e, 'sentence': sentence, 'method':'rule_based', 'relation':'uncertain','score':0.0, 'id': entry.get('id')}\n",
    "            if sentence_contains_cue(sentence):\n",
    "                r['relation'] = 'adverse_effect'\n",
    "                r['score'] = 0.9\n",
    "            else:\n",
    "                try:\n",
    "                    dpos = next((i for i,t in enumerate(tokens) if t == simple_normalize(d).split()[0]), None)\n",
    "                    epos = next((i for i,t in enumerate(tokens) if t == simple_normalize(e).split()[0]), None)\n",
    "                    if dpos is not None and epos is not None and abs(dpos-epos) <= 6:\n",
    "                        r['relation'] = 'adverse_effect'\n",
    "                        r['score'] = 0.6\n",
    "                    else:\n",
    "                        r['relation'] = 'not_related'\n",
    "                        r['score'] = 0.2\n",
    "                except Exception:\n",
    "                    r['relation'] = 'uncertain'\n",
    "                    r['score'] = 0.1\n",
    "            relations.append(r)\n",
    "    if not drugs and events:\n",
    "        for e in events:\n",
    "            relations.append({'drug': None, 'event': e, 'sentence': sentence, 'method':'rule_based','relation':'not_related','score':0.0,'id':entry.get('id')})\n",
    "    return relations\n",
    "\n",
    "# Run relation extraction on results/extractions.json\n",
    "extractions = load_json('results/extractions.json')\n",
    "all_relations = []\n",
    "for entry in extractions:\n",
    "    rels = relation_rule_based(entry)\n",
    "    all_relations.extend(rels)\n",
    "\n",
    "save_json(all_relations, 'results/relations.json')\n",
    "print(f'Extracted {len(all_relations)} relations. Saved to results/relations.json')\n",
    "import pandas as pd\n",
    "df_rel = pd.DataFrame(all_relations)\n",
    "df_rel.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization: map drugs -> drug_id/atc, events -> meddra code using simple fuzzy matching\n",
    "drugs_map = load_dict_csv('data/dictionaries/drugs.csv', key_col='name')\n",
    "meddra_map = load_dict_csv('data/dictionaries/meddra.csv', key_col='term')\n",
    "drug_candidates = list(drugs_map.keys())\n",
    "event_candidates = list(meddra_map.keys())\n",
    "\n",
    "def normalize_relations(relations: List[dict]):\n",
    "    normalized = []\n",
    "    for r in relations:\n",
    "        dr = r.get('drug')\n",
    "        ev = r.get('event')\n",
    "        drn = simple_normalize(dr) if dr else ''\n",
    "        evn = simple_normalize(ev) if ev else ''\n",
    "        drug_match, dscore = fuzzy_match_difflib(drn, drug_candidates, cutoff=0.6) if drn else (None, 0.0)\n",
    "        event_match, escore = fuzzy_match_difflib(evn, event_candidates, cutoff=0.6) if evn else (None, 0.0)\n",
    "        out = dict(r)\n",
    "        if drug_match:\n",
    "            out['drug_normalized_name'] = drug_match\n",
    "            out['drug_id'] = drugs_map[drug_match].get('id')\n",
    "            out['drug_atc'] = drugs_map[drug_match].get('atc')\n",
    "            out['drug_match_score'] = round(dscore,3)\n",
    "        else:\n",
    "            out['drug_normalized_name'] = drn or None\n",
    "            out['drug_id'] = None\n",
    "            out['drug_atc'] = None\n",
    "            out['drug_match_score'] = round(dscore,3)\n",
    "        if event_match:\n",
    "            out['event_normalized_term'] = event_match\n",
    "            out['event_code'] = meddra_map[event_match].get('code')\n",
    "            out['event_match_score'] = round(escore,3)\n",
    "        else:\n",
    "            out['event_normalized_term'] = evn or None\n",
    "            out['event_code'] = None\n",
    "            out['event_match_score'] = round(escore,3)\n",
    "        normalized.append(out)\n",
    "    return normalized\n",
    "\n",
    "normalized = normalize_relations(all_relations)\n",
    "save_json(normalized, 'results/normalized.json')\n",
    "print(f'Saved {len(normalized)} normalized relations to results/normalized.json')\n",
    "import pandas as pd\n",
    "df_norm = pd.DataFrame(normalized)\n",
    "df_norm.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faa27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization (extractive baseline): simple first-2-sentences approach\n",
    "def extractive_summary(text: str, n_sent=2):\n",
    "    if not text or not text.strip():\n",
    "        return ''\n",
    "    sents = re.split(r'(?<=[.!?])\\\\s+', text.strip())\n",
    "    return ' '.join(sents[:n_sent])\n",
    "\n",
    "summaries = []\n",
    "for entry in extractions:\n",
    "    txt = entry.get('sentence','')\n",
    "    summ = extractive_summary(txt, n_sent=2)\n",
    "    summaries.append({'id': entry.get('id'), 'summary_extractive': summ})\n",
    "\n",
    "save_json(summaries, 'results/summaries.json')\n",
    "print(f'Saved {len(summaries)} extractive summaries to results/summaries.json')\n",
    "import pandas as pd\n",
    "pd.DataFrame(summaries).head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94087809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small manual annotation set for evaluation.\n",
    "manual_annotations = [\n",
    "    {'id':'doc1_sent1','drug':'paracetamol','event':'nausea','label':'adverse_effect'},\n",
    "    {'id':'doc1_sent2','drug':'ibuprofen','event':'stomach pain','label':'adverse_effect'},\n",
    "    {'id':'doc1_sent2','drug':'ibuprofen','event':'vomiting','label':'adverse_effect'},\n",
    "    {'id':'doc2_sent1','drug':'metformin','event':'headache','label':'adverse_effect'},\n",
    "    {'id':'doc3_sent2','drug':None,'event':'dizziness','label':'not_related'},\n",
    "    {'id':'doc4_sent1','drug':'amoxicillin','event':'rash','label':'adverse_effect'},\n",
    "    {'id':'doc5_sent1','drug':'paracetamol','event':'vomiting','label':'uncertain'}\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "df_pred = pd.DataFrame(normalized)\n",
    "df_pred_eval = df_pred[['id','drug','event','relation','score']].copy()\n",
    "df_truth = pd.DataFrame(manual_annotations)\n",
    "df_truth['drug'] = df_truth['drug'].where(df_truth['drug'].notnull(), None)\n",
    "\n",
    "merged = pd.merge(df_truth, df_pred_eval, on=['id','drug','event'], how='left', suffixes=('_truth','_pred'))\n",
    "merged['relation'] = merged['relation'].fillna('not_found')\n",
    "\n",
    "def compute_metrics(df, positive_label='adverse_effect'):\n",
    "    tp = ((df['label']==positive_label) & (df['relation']==positive_label)).sum()\n",
    "    fp = ((df['label']!=positive_label) & (df['relation']==positive_label)).sum()\n",
    "    fn = ((df['label']==positive_label) & (df['relation']!=positive_label)).sum()\n",
    "    precision = tp / (tp+fp) if (tp+fp)>0 else 0.0\n",
    "    recall = tp / (tp+fn) if (tp+fn)>0 else 0.0\n",
    "    f1 = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0.0\n",
    "    return {'tp':int(tp),'fp':int(fp),'fn':int(fn),'precision':round(precision,3),'recall':round(recall,3),'f1':round(f1,3)}\n",
    "\n",
    "metrics = compute_metrics(merged)\n",
    "print('Evaluation metrics (rule-based):')\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f355c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: top drugs by ADE count and relation distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_norm_local = df_norm.copy()\n",
    "df_ade = df_norm_local[df_norm_local['relation']=='adverse_effect'].copy()\n",
    "top_drugs = df_ade['drug_normalized_name'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "top_drugs.plot(kind='bar')\n",
    "plt.title('Top drugs by adverse_effect count (rule-based)')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Drug (normalized)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "rel_counts = df_norm_local['relation'].value_counts()\n",
    "plt.figure(figsize=(6,4))\n",
    "rel_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "plt.ylabel('')\n",
    "plt.title('Relation label distribution (rule-based)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final notes & how to adapt this notebook for your real pipeline\n",
    "\n",
    "notes_lines = [\n",
    "    '- Replace results/extractions.json with the Person2 output (keep fields: id, sentence, drugs[], events[])',\n",
    "    '- Replace data/dictionaries/drugs.csv and data/dictionaries/meddra.csv with your fuller dictionaries',\n",
    "    '- Optionally improve normalization using fuzzywuzzy or a proper UMLS lookup (if available)',\n",
    "    '- To add LLM-based relation disambiguation: implement a function that calls your LLM (OpenAI or local), send a few-shot prompt, and parse JSON response',\n",
    "    '- For borderline relations (score<0.8) you can call the LLM to refine the label',\n",
    "    '- To expose Person7 as an API endpoint: embed main functions into a FastAPI endpoint (e.g., /person7/relations) and call from Person4 backend',\n",
    "    'This notebook saved: results/relations.json, results/normalized.json, results/summaries.json',\n",
    "    'Upload these files to GitHub as part of your case study.'\n",
    "]\n",
    "for line in notes_lines:\n",
    "    print(line)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
